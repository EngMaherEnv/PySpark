{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae950305",
   "metadata": {},
   "source": [
    "# NLP in Pyspark's MLlib\n",
    "\n",
    "Natural Language Processing (NLP) is a very trendy topic in the data science area today that is really handy for tasks like **chat bots**, movie or **product review analysis** and especially **tweet classification**. In this notebook, we will cover the **classification aspect of NLP** and go over the features that Spark has for cleaning and preparing your data for analysis. We will also touch on how to implement **ML Pipelines** to a few of our data processing steps to help make our code run a bit faster. \n",
    "\n",
    "The text you process must first be cleaned, tokenized and vectorized. Essentially, we need to covert our text into a vector of numbers. But how do we do that? Spark has a variety of built in functions to accomplish all of these tasks very easily. We will cover all of it here!\n",
    "\n",
    "### Agenda\n",
    "\n",
    "    1. Review Data (quality check)\n",
    "    2. Clean up the data (remove puncuation, special characters, etc.)\n",
    "    3. Tokenize text data\n",
    "    4. Remove Stopwords\n",
    "    5. Zero index our label column\n",
    "    5. Create an ML Pipeline (to streamline steps 3-5)\n",
    "    6. Vectorize Text column\n",
    "         - Count Vectors\n",
    "         - TF-IDF\n",
    "         - Word2Vec\n",
    "    7. Train and Evaluate Model (classification)\n",
    "    8. View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8951fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MaherAlrefaai.Pressdom.local:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2744e46bd30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's create our PySpark instance\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d0ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import * #CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import * #col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import * #StringType,IntegerType\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# For pipeline development\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afc324",
   "metadata": {},
   "source": [
    "# Read in Dataset\n",
    "\n",
    "#### Kickstarter Dataset\n",
    "\n",
    "##### What is Kickstarter?\n",
    "\"Kickstarter is an American public-benefit corporation based in Brooklyn, New York, that maintains a global crowdfunding platform, focused on creativity and merchandising. The company's stated mission is to \"help bring creative projects to life\". Kickstarter, has reportedly received more than $1.9 billion in pledges from 9.4 million backers to fund 257,000 creative projects, such as films, music, stage shows, comics, journalism, video games, technology and food-related projects.\n",
    "\n",
    "People who back Kickstarter projects are offered tangible rewards or experiences in exchange for their pledges. This model traces its roots to subscription model of arts patronage, where artists would go directly to their audiences to fund their work\" ~ Wikipedia\n",
    "\n",
    "So, what if you can predict if a project will be or not to be able to get the money from their backers?\n",
    "\n",
    "#### Content\n",
    "\n",
    "The datastet contains the blurbs or short description of 215,513 projects runned along 2017, all written in english and all labeled with \"successful\" or \"failed\", if they get the money or not, respectively. From those texts you can train linguistics models for description, and even embeddings relative to the case.\n",
    "\n",
    "**Source:** https://www.kaggle.com/oscarvilla/kickstarter-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade0b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"Datasets/\"\n",
    "\n",
    "# CSV\n",
    "df = spark.read.csv(path+'kickstarter.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b039c719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using their own character, users go on educati...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MicroFly is a quadcopter packed with WiFi, 6 s...</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A small indie press, run as a collective for a...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Zylor is a new baby cosplayer! Back this kicks...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hatoful Boyfriend meet Skeletons! A comedy Dat...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223622</th>\n",
       "      <td>215509</td>\n",
       "      <td>This new, designer approach to family wall art...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223623</th>\n",
       "      <td>215510</td>\n",
       "      <td>Im looking to build a urban youth center to he...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223624</th>\n",
       "      <td>215511</td>\n",
       "      <td>My plan is to create the most realistic and ac...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223625</th>\n",
       "      <td>215512</td>\n",
       "      <td>Create unique and fantastic gifts: Mash works ...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223626</th>\n",
       "      <td>215513</td>\n",
       "      <td>Currently running a shop on Zazzle come and wo...</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223627 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _c0                                              blurb       state\n",
       "0            1  Using their own character, users go on educati...      failed\n",
       "1            2  MicroFly is a quadcopter packed with WiFi, 6 s...  successful\n",
       "2            3  A small indie press, run as a collective for a...      failed\n",
       "3            4  Zylor is a new baby cosplayer! Back this kicks...      failed\n",
       "4            5  Hatoful Boyfriend meet Skeletons! A comedy Dat...      failed\n",
       "...        ...                                                ...         ...\n",
       "223622  215509  This new, designer approach to family wall art...      failed\n",
       "223623  215510  Im looking to build a urban youth center to he...      failed\n",
       "223624  215511  My plan is to create the most realistic and ac...      failed\n",
       "223625  215512  Create unique and fantastic gifts: Mash works ...      failed\n",
       "223626  215513  Currently running a shop on Zazzle come and wo...      failed\n",
       "\n",
       "[223627 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaae46a",
   "metadata": {},
   "source": [
    "# How many null values do we have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43ae701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------+\n",
      "|Column_Name|Null_Values_Count|Null_Value_Percent|\n",
      "+-----------+-----------------+------------------+\n",
      "|      blurb|             1488|0.6653937136392296|\n",
      "|      state|            13157| 5.883457722010312|\n",
      "+-----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "def null_value_calc(df):\n",
    "    null_columns_counts = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        nullRows = df.where(col(k).isNull()).count()\n",
    "        if(nullRows > 0):\n",
    "            temp = k,nullRows,(nullRows/numRows)*100\n",
    "            null_columns_counts.append(temp)\n",
    "    return(null_columns_counts)\n",
    "\n",
    "null_columns_calc_list = null_value_calc(df)\n",
    "spark.createDataFrame(null_columns_calc_list, ['Column_Name', 'Null_Values_Count','Null_Value_Percent']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6036d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values\n",
    "# It's only about 6% so that's okay\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28cbf48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210470"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New df row count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c153c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+------+\n",
      "|state                                                      |count |\n",
      "+-----------------------------------------------------------+------+\n",
      "|successful                                                 |103582|\n",
      "|failed                                                     |102000|\n",
      "| and get some collectible prints for yourself!\"            |8     |\n",
      "| their childhood                                           |6     |\n",
      "|\",\"failed\"                                                 |6     |\n",
      "| love                                                      |6     |\n",
      "| about a lonely frustrated man struggling with his sanity.\"|5     |\n",
      "| poetry                                                    |4     |\n",
      "| romance                                                   |4     |\n",
      "| mastered                                                  |4     |\n",
      "| 2011.\"                                                    |3     |\n",
      "| 2015.\"                                                    |3     |\n",
      "| racism                                                    |3     |\n",
      "| 2014.\"                                                    |3     |\n",
      "| betrayal                                                  |3     |\n",
      "| CD                                                        |3     |\n",
      "| faith                                                     |3     |\n",
      "| Texas.\"                                                   |3     |\n",
      "| music                                                     |3     |\n",
      "| 2014\"                                                     |3     |\n",
      "+-----------------------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick data quality check on the state column....\n",
    "# This is going to be our category column so it's important\n",
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d5eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|state     |count |\n",
      "+----------+------+\n",
      "|successful|103582|\n",
      "|failed    |102000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(\"state IN('successful','failed')\")\n",
    "# Make sure it worked\n",
    "df.groupBy(\"state\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9229b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                             |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character, users go on educational quests around a virtual world leveling up subject-oriented skills  ie Physics .|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace Slashes and parenthesis with spaces\n",
    "# You can test your script on line 7 of the df \"(Legend of Zelda/Fable Inspired)\"\n",
    "df = df.withColumn(\"blurb\",translate(col(\"blurb\"), \"/\", \" \")) \\\n",
    "        .withColumn(\"blurb\",translate(col(\"blurb\"), \"(\", \" \")) \\\n",
    "        .withColumn(\"blurb\",translate(col(\"blurb\"), \")\", \" \"))\n",
    "df.select(\"blurb\").show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "165a5759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character users go on educational quests around a virtual world leveling up subjectoriented skills  ie Physics |\n",
      "|MicroFly is a quadcopter packed with WiFi  sensors and  processors for ultimate stability  and fits in the palm of your hand   |\n",
      "|A small indie press run as a collective for authors who want to selfpublish and a sexy smart  hilarious novel                  |\n",
      "|Zylor is a new baby cosplayer Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world  |\n",
      "|Hatoful Boyfriend meet Skeletons A comedy Dating Sim that puts you into a high school full of Skeletons Rattle some Bones      |\n",
      "|FastMan is a Infinite running platformer Go in FastMans shoes and run through the platform dodging obstacles                   |\n",
      "|FADE A dark and somber RPG about survival and hope Legend of Zelda Fable Inspired                                              |\n",
      "|The next generation of space combat with online progression leveling an arsenal of ships weapons and much more                 |\n",
      "|Whip around planets and smash your way to victory in this video game of galactic proportions                                   |\n",
      "|Sneak in find treasures avoid cats and collect the loot before time runs out                                                   |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing anything that is not a letter\n",
    "df = df.withColumn(\"blurb\",regexp_replace(col('blurb'), '[^A-Za-z ]+', ''))\n",
    "df.select(\"blurb\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6834fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie Physics |\n",
      "|MicroFly is a quadcopter packed with WiFi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|A small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|Zylor is a new baby cosplayer Back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove multiple spaces\n",
    "df = df.withColumn(\"blurb\",regexp_replace(col('blurb'), ' +', ' '))\n",
    "df.select(\"blurb\").show(4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2e37bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|blurb                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |\n",
      "|microfly is a quadcopter packed with wifi sensors and processors for ultimate stability and fits in the palm of your hand     |\n",
      "|a small indie press run as a collective for authors who want to selfpublish and a sexy smart hilarious novel                  |\n",
      "|zylor is a new baby cosplayer back this kickstarter to help fund new cosplay photoshoots to share his cuteness with the world |\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lower case everything\n",
    "df = df.withColumn(\"blurb\",lower(col('blurb')))\n",
    "df.select(\"blurb\").show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa421d",
   "metadata": {},
   "source": [
    "# Prep Data for NLP \n",
    "\n",
    "Alright so here is where our analysis turns from basic text cleaning to actually turning our text into number (the backbone of NLP). These next several steps in our analysis are very unique to NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4bc369",
   "metadata": {},
   "source": [
    "# Split text into words (Tokenizing)\n",
    "\n",
    "Yo'll see a new column is added to our dataframe that we call \"words\". This column contains an array of strings as opposed to just a string (current data type of the blurb column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91bf69ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>hatoful boyfriend meet skeletons a comedy dati...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[hatoful, boyfriend, meet, skeletons, a, comed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205577</th>\n",
       "      <td>215509</td>\n",
       "      <td>this new designer approach to family wall art ...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[this, new, designer, approach, to, family, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205578</th>\n",
       "      <td>215510</td>\n",
       "      <td>im looking to build a urban youth center to he...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[im, looking, to, build, a, urban, youth, cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205579</th>\n",
       "      <td>215511</td>\n",
       "      <td>my plan is to create the most realistic and ac...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[my, plan, is, to, create, the, most, realisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205580</th>\n",
       "      <td>215512</td>\n",
       "      <td>create unique and fantastic gifts mash works o...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[create, unique, and, fantastic, gifts, mash, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205581</th>\n",
       "      <td>215513</td>\n",
       "      <td>currently running a shop on zazzle come and wo...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[currently, running, a, shop, on, zazzle, come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205582 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _c0                                              blurb       state  \\\n",
       "0            1  using their own character users go on educatio...      failed   \n",
       "1            2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2            3  a small indie press run as a collective for au...      failed   \n",
       "3            4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "4            5  hatoful boyfriend meet skeletons a comedy dati...      failed   \n",
       "...        ...                                                ...         ...   \n",
       "205577  215509  this new designer approach to family wall art ...      failed   \n",
       "205578  215510  im looking to build a urban youth center to he...      failed   \n",
       "205579  215511  my plan is to create the most realistic and ac...      failed   \n",
       "205580  215512  create unique and fantastic gifts mash works o...      failed   \n",
       "205581  215513  currently running a shop on zazzle come and wo...      failed   \n",
       "\n",
       "                                                    words  \n",
       "0       [using, their, own, character, users, go, on, ...  \n",
       "1       [microfly, is, a, quadcopter, packed, with, wi...  \n",
       "2       [a, small, indie, press, run, as, a, collectiv...  \n",
       "3       [zylor, is, a, new, baby, cosplayer, back, thi...  \n",
       "4       [hatoful, boyfriend, meet, skeletons, a, comed...  \n",
       "...                                                   ...  \n",
       "205577  [this, new, designer, approach, to, family, wa...  \n",
       "205578  [im, looking, to, build, a, urban, youth, cent...  \n",
       "205579  [my, plan, is, to, create, the, most, realisti...  \n",
       "205580  [create, unique, and, fantastic, gifts, mash, ...  \n",
       "205581  [currently, running, a, shop, on, zazzle, come...  \n",
       "\n",
       "[205582 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"blurb\", outputCol=\"words\", pattern=\"\\W\")\n",
    "raw_words = regex_tokenizer.transform(df)\n",
    "raw_words.toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf41a6b",
   "metadata": {},
   "source": [
    "# Removing Stopwords\n",
    "\n",
    "Recall that \"stopwords\" are any word that we feel would \"distract\" our model from performing it's best. This list can be customized, but for now, we will just use the default list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be6667c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0|blurb                                                                                                                         |state |words                                                                                                                                            |filtered                                                                                                                  |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed|[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|[using, character, users, go, educational, quests, around, virtual, world, leveling, subjectoriented, skills, ie, physics]|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Define a list of stop words or use default list\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "stopwords = remover.getStopWords() \n",
    "\n",
    "# Display default list\n",
    "stopwords[:10]\n",
    "\n",
    "\n",
    "words_df = remover.transform(raw_words)\n",
    "words_df.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd43937",
   "metadata": {},
   "source": [
    "# Now we need to encode state column to a column of indices\n",
    "\n",
    "Remember that MLlib requres our dependent variable to not only be a numeric data type, but also zero indexed. We can Sparks handy built in StringIndexer function to accomplish this, just like we did in the classification lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe390b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+--------------------+--------------------+-----+\n",
      "|_c0|               blurb|     state|               words|            filtered|label|\n",
      "+---+--------------------+----------+--------------------+--------------------+-----+\n",
      "|  1|using their own c...|    failed|[using, their, ow...|[using, character...|  1.0|\n",
      "|  2|microfly is a qua...|successful|[microfly, is, a,...|[microfly, quadco...|  0.0|\n",
      "|  3|a small indie pre...|    failed|[a, small, indie,...|[small, indie, pr...|  1.0|\n",
      "|  4|zylor is a new ba...|    failed|[zylor, is, a, ne...|[zylor, new, baby...|  1.0|\n",
      "|  5|hatoful boyfriend...|    failed|[hatoful, boyfrie...|[hatoful, boyfrie...|  1.0|\n",
      "+---+--------------------+----------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- blurb: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"state\", outputCol=\"label\")\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "feature_data.show(5)\n",
    "feature_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be96a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>blurb</th>\n",
       "      <th>state</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>using their own character users go on educatio...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[using, their, own, character, users, go, on, ...</td>\n",
       "      <td>[using, character, users, go, educational, que...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>microfly is a quadcopter packed with wifi sens...</td>\n",
       "      <td>successful</td>\n",
       "      <td>[microfly, is, a, quadcopter, packed, with, wi...</td>\n",
       "      <td>[microfly, quadcopter, packed, wifi, sensors, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a small indie press run as a collective for au...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[a, small, indie, press, run, as, a, collectiv...</td>\n",
       "      <td>[small, indie, press, run, collective, authors...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>zylor is a new baby cosplayer back this kickst...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[zylor, is, a, new, baby, cosplayer, back, thi...</td>\n",
       "      <td>[zylor, new, baby, cosplayer, back, kickstarte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>hatoful boyfriend meet skeletons a comedy dati...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[hatoful, boyfriend, meet, skeletons, a, comed...</td>\n",
       "      <td>[hatoful, boyfriend, meet, skeletons, comedy, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205577</th>\n",
       "      <td>215509</td>\n",
       "      <td>this new designer approach to family wall art ...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[this, new, designer, approach, to, family, wa...</td>\n",
       "      <td>[new, designer, approach, family, wall, art, h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205578</th>\n",
       "      <td>215510</td>\n",
       "      <td>im looking to build a urban youth center to he...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[im, looking, to, build, a, urban, youth, cent...</td>\n",
       "      <td>[im, looking, build, urban, youth, center, hel...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205579</th>\n",
       "      <td>215511</td>\n",
       "      <td>my plan is to create the most realistic and ac...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[my, plan, is, to, create, the, most, realisti...</td>\n",
       "      <td>[plan, create, realistic, accurate, reconstruc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205580</th>\n",
       "      <td>215512</td>\n",
       "      <td>create unique and fantastic gifts mash works o...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[create, unique, and, fantastic, gifts, mash, ...</td>\n",
       "      <td>[create, unique, fantastic, gifts, mash, works...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205581</th>\n",
       "      <td>215513</td>\n",
       "      <td>currently running a shop on zazzle come and wo...</td>\n",
       "      <td>failed</td>\n",
       "      <td>[currently, running, a, shop, on, zazzle, come...</td>\n",
       "      <td>[currently, running, shop, zazzle, come, like,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205582 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _c0                                              blurb       state  \\\n",
       "0            1  using their own character users go on educatio...      failed   \n",
       "1            2  microfly is a quadcopter packed with wifi sens...  successful   \n",
       "2            3  a small indie press run as a collective for au...      failed   \n",
       "3            4  zylor is a new baby cosplayer back this kickst...      failed   \n",
       "4            5  hatoful boyfriend meet skeletons a comedy dati...      failed   \n",
       "...        ...                                                ...         ...   \n",
       "205577  215509  this new designer approach to family wall art ...      failed   \n",
       "205578  215510  im looking to build a urban youth center to he...      failed   \n",
       "205579  215511  my plan is to create the most realistic and ac...      failed   \n",
       "205580  215512  create unique and fantastic gifts mash works o...      failed   \n",
       "205581  215513  currently running a shop on zazzle come and wo...      failed   \n",
       "\n",
       "                                                    words  \\\n",
       "0       [using, their, own, character, users, go, on, ...   \n",
       "1       [microfly, is, a, quadcopter, packed, with, wi...   \n",
       "2       [a, small, indie, press, run, as, a, collectiv...   \n",
       "3       [zylor, is, a, new, baby, cosplayer, back, thi...   \n",
       "4       [hatoful, boyfriend, meet, skeletons, a, comed...   \n",
       "...                                                   ...   \n",
       "205577  [this, new, designer, approach, to, family, wa...   \n",
       "205578  [im, looking, to, build, a, urban, youth, cent...   \n",
       "205579  [my, plan, is, to, create, the, most, realisti...   \n",
       "205580  [create, unique, and, fantastic, gifts, mash, ...   \n",
       "205581  [currently, running, a, shop, on, zazzle, come...   \n",
       "\n",
       "                                                 filtered  label  \n",
       "0       [using, character, users, go, educational, que...    1.0  \n",
       "1       [microfly, quadcopter, packed, wifi, sensors, ...    0.0  \n",
       "2       [small, indie, press, run, collective, authors...    1.0  \n",
       "3       [zylor, new, baby, cosplayer, back, kickstarte...    1.0  \n",
       "4       [hatoful, boyfriend, meet, skeletons, comedy, ...    1.0  \n",
       "...                                                   ...    ...  \n",
       "205577  [new, designer, approach, family, wall, art, h...    1.0  \n",
       "205578  [im, looking, build, urban, youth, center, hel...    1.0  \n",
       "205579  [plan, create, realistic, accurate, reconstruc...    1.0  \n",
       "205580  [create, unique, fantastic, gifts, mash, works...    1.0  \n",
       "205581  [currently, running, shop, zazzle, come, like,...    1.0  \n",
       "\n",
       "[205582 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de32c1",
   "metadata": {},
   "source": [
    "# Creat an ML Pipeline\n",
    "\n",
    "We could also create an ML Pipeline to accomplish the previous three steps in a more streamlined fashion. Pipelines allow users to combine any transformer call(s) and ONE estimator call in their ML workflow. Si a Pipeline can be a continuous set of transformer calls until you reach a point where you need to call \".fit()\" which is an estimator call. \n",
    "<br>\n",
    "\n",
    "Notice in the script below that we reduced our .transform calls from 3 to 1. So the benefit here is not necessarily speed but a bit less and more organized code (always nice) and little more streamlined. This feature can be esspecially useful when you get to the point where you want to move your model into production. You can save this pipeline to be called on whenever you need to prep new text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d27ab14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|_c0|blurb                                                                                                                         |state |words                                                                                                                                            |filtered                                                                                                                  |label|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1  |using their own character users go on educational quests around a virtual world leveling up subjectoriented skills ie physics |failed|[using, their, own, character, users, go, on, educational, quests, around, a, virtual, world, leveling, up, subjectoriented, skills, ie, physics]|[using, character, users, go, educational, quests, around, virtual, world, leveling, subjectoriented, skills, ie, physics]|1.0  |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################## BEFORE #############################\n",
    "# Tokenize\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"blurb\", outputCol=\"words\", pattern=\"\\\\W\") # These also work as well: \"\\W\", r\"\\W\"\n",
    "raw_words = regex_tokenizer.transform(df)\n",
    "\n",
    "# Remove Stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = remover.transform(raw_words)\n",
    "\n",
    "# Zero Index Label Column\n",
    "indexer = StringIndexer(inputCol=\"state\", outputCol=\"label\")\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "\n",
    "feature_data.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# AFTER ##################\n",
    "\n",
    "# Tokenize\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"blurb\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# raw_words = regex_tokenizer.transform(df)\n",
    "\n",
    "# Remove Stop words\n",
    "remover = StopWordsRemover(inputCol=regex_tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# words_df = remover.transform(raw_words)\n",
    "\n",
    "# Zero Index Label Column\n",
    "indexer = StringIndexer(inputCol=\"state\", outputCol=\"label\")\n",
    "# feature_data = indexer.fit(words_df).transform(words_df)\n",
    "\n",
    "# Create the Pipeline\n",
    "pipeline = Pipeline(stages=[regex_tokenizer,remover,indexer])\n",
    "data_prep_pl = pipeline.fit(df)\n",
    "# print(type(data_prep_pl))\n",
    "# print(\" \")\n",
    "# Now call on the Pipeline to get our final df\n",
    "feature_data = data_prep_pl.transform(df)\n",
    "feature_data.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948923a3",
   "metadata": {},
   "source": [
    "# Converting text into vectors\n",
    "\n",
    "We will test out the following three vectorizors:\n",
    "\n",
    "1. Count Vectors\n",
    "2. TF-IDF\n",
    "3. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6390d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vector (count vectorizer and hashingTF are basically the same thing)\n",
    "# cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "# model = cv.fit(feature_data)\n",
    "# countVectorizer_features = model.transform(feature_data)\n",
    "\n",
    "# Hashing TF\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=20)\n",
    "HTFfeaturizedData = hashingTF.transform(feature_data)\n",
    "\n",
    "# TF-IDF\n",
    "idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData.name = 'TFIDFfeaturizedData'\n",
    "\n",
    "#rename the HTF features to features to be consistent\n",
    "HTFfeaturizedData = HTFfeaturizedData.withColumnRenamed(\"rawfeatures\",\"features\")\n",
    "HTFfeaturizedData.name = 'HTFfeaturizedData' #We will use later for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c747678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = word2Vec.fit(feature_data)\n",
    "\n",
    "W2VfeaturizedData = model.transform(feature_data)\n",
    "# W2VfeaturizedData.show(1,False)\n",
    "\n",
    "# W2Vec Dataframes typically has negative values so we will correct for that here so that we can use the Naive Bayes classifier\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scaler.fit(W2VfeaturizedData)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_data = scalerModel.transform(W2VfeaturizedData)\n",
    "W2VfeaturizedData = scaled_data.select('state','blurb','label','scaledFeatures')\n",
    "W2VfeaturizedData = W2VfeaturizedData.withColumnRenamed('scaledFeatures','features')\n",
    "\n",
    "W2VfeaturizedData.name = 'W2VfeaturizedData' # We will need this to print later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67841ef1",
   "metadata": {},
   "source": [
    "# Train and Evaluate your model\n",
    "\n",
    "From here on out, is straight up classification. So we can go and use our trusty function! I'll just go ahead and copy and paste it in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "429dc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Extract list of binary models\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype,\" Weights\"+ '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Estimate of the importance of each feature.\n",
    "            # Each featureâ€™s importance is the average of its importance across all trees \n",
    "            # in the ensemble The importance vector is normalized to sum to 1. \n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            print(BestModel.featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureimportances\n",
    "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureimportances\n",
    "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureimportances\n",
    "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c54ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import *\n",
    "# from pyspark.ml.evaluation import *\n",
    "# from pyspark.sql import functions\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "featureDF_list = [HTFfeaturizedData,TFIDFfeaturizedData,W2VfeaturizedData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a105a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHTFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.0256933 ,  0.0097964 , -0.08864652,  0.0051675 , -0.01329618,\n",
      "              -0.1108607 , -0.06274444, -0.0296108 , -0.02705734, -0.03988526,\n",
      "               0.06202708, -0.02634176,  0.00827497,  0.01186311, -0.02741348,\n",
      "              -0.03220964,  0.0108462 , -0.01966571, -0.08667609, -0.02457991]])\n",
      "Intercept: [0.26544015119000186]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.24966694800931863 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.02437200909638509,-0.009948587949845817,0.08473281956530092,-0.005427651832218895,0.012376310128827098,0.10637823977431714,0.06005277951052893,0.02824710307215877,0.025650201010601732,0.03786481650113965,-0.05997334073039995,0.024862405502293447,-0.00848600680489792,-0.011890008216663639,0.025886128537200574,0.03041032842934641,-0.010888816661292867,0.018630992297956138,0.08300530179635958,0.023091229696537794]\n",
      "\u001b[1mIntercept: \u001b[0m 0.24966694800931927 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.024372009096385122,0.00994858794984578,-0.08473281956530097,0.005427651832218847,-0.012376310128827164,-0.10637823977431715,-0.06005277951052898,-0.028247103072158813,-0.025650201010601788,-0.037864816501139695,0.05997334073039993,-0.024862405502293454,0.00848600680489787,0.011890008216663571,-0.025886128537200646,-0.03041032842934647,0.010888816661292794,-0.018630992297956225,-0.08300530179635966,-0.023091229696537822]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.031067260660515687,0.0971440053626683,-0.2818659503441581,0.0728577567169658,-0.0064454363112159095,-0.30614578238870466,-0.16752729773879185,-0.04795610706086646,-0.05417360260665232,-0.10595397425733472,0.2754673242586746,-0.054835972808911324,0.0799987378416329,0.10219436351149319,-0.054055696844767444,-0.07084833852498389,0.09168415437119373,-0.02127421917182008,-0.24398828828875294,-0.0378427798144896]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0438239357882006,0.041997321173032585,0.07121280569564908,0.04671367243445568,0.03702703622919089,0.10061855176581973,0.05403560605577094,0.04458691965263318,0.0429352295747948,0.0393144373561788,0.07140595248855418,0.038958118606623925,0.048534140166431414,0.04638326158833885,0.045256892531478306,0.043051153387956356,0.04033527821738834,0.043050390015552574,0.057306967410384005,0.043452329861565823])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.034165686688606096,0.040549601522082195,0.048477574394662375,0.05929986310580735,0.03668090170300709,0.0702997328677569,0.09322641809438295,0.0615246650732552,0.027459722737612848,0.04273922087259942,0.06616155834340433,0.039306814873595296,0.03494110450285985,0.04695038351898258,0.0635787662122594,0.04406889747229029,0.034617758514257226,0.06005882117055409,0.04904248073110731,0.0468500276009173])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,2,4,5,6,7,8,10,12,15,18,19],[0.008101773017722172,0.22400260258264165,0.012857958649547608,0.3809726925253951,0.04158612397023884,0.030330022537158566,0.012662457049250824,0.10171669755393883,0.017610860848471178,0.013962837799693654,0.14174137698126102,0.014454596484680577])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.61 |\n",
      "|OneVsRest                     |52.64 |\n",
      "|LinearSVC                     |52.48 |\n",
      "|NaiveBayes                    |52.31 |\n",
      "|RandomForestClassifier        |52.52 |\n",
      "|GBTClassifier                 |52.37 |\n",
      "|DecisionTreeClassifier        |52.25 |\n",
      "|MultilayerPerceptronClassifier|52.81 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mTFIDFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.03422504,  0.01040123, -0.09943087,  0.00777224, -0.01442063,\n",
      "              -0.14463955, -0.07960162, -0.03967817, -0.03382424, -0.04481261,\n",
      "               0.08230706, -0.02628582,  0.00949303,  0.01797726, -0.03384962,\n",
      "              -0.03853393,  0.01104422, -0.02633592, -0.09046069, -0.02696032]])\n",
      "Intercept: [0.26544015119000225]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.24966694800931885 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.03246500693330013,-0.0105628139051537,0.09504105218173263,-0.008163520136026498,0.013422965504346759,0.13879130382823474,0.07618680479394639,0.037850825357983585,0.03206518259229216,0.0425425624747752,-0.07958184339447834,0.024809613883423415,-0.00973513555101138,-0.018018029095214716,0.03196368188228229,0.03638133107746399,-0.011087613153968182,0.024950241255234068,0.08662962215660133,0.02532746776305455]\n",
      "\u001b[1mIntercept: \u001b[0m 0.24966694800931818 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.03246500693330009,0.010562813905153741,-0.09504105218173257,0.008163520136026562,-0.013422965504346723,-0.13879130382823465,-0.07618680479394635,-0.037850825357983515,-0.032065182592292074,-0.04254256247477519,0.07958184339447845,-0.02480961388342338,0.009735135551011454,0.018018029095214817,-0.03196368188228222,-0.036381331077463906,0.011087613153968237,-0.02495024125523398,-0.08662962215660126,-0.025327467763054497]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.04138349156007342,0.10314167757475741,-0.31615655695568307,0.10958251973607618,-0.006990522083346579,-0.3994272925495577,-0.21253586652462708,-0.06426068643473448,-0.06772213826108597,-0.119043322688695,0.3655323714247859,-0.05471953677955787,0.0917744440587315,0.15486457044970134,-0.06674691023758944,-0.0847592575711315,0.09335802664674482,-0.028489996258109797,-0.25464172489783726,-0.041507611262451005]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0438239357882006,0.041997321173032585,0.07121280569564908,0.04671367243445568,0.03702703622919089,0.10061855176581973,0.05403560605577094,0.04458691965263318,0.0429352295747948,0.0393144373561788,0.07140595248855418,0.038958118606623925,0.048534140166431414,0.04638326158833885,0.045256892531478306,0.043051153387956356,0.04033527821738834,0.043050390015552574,0.057306967410384005,0.043452329861565823])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.034165686688606096,0.040549601522082195,0.048477574394662375,0.05929986310580735,0.03668090170300709,0.0702997328677569,0.09322641809438295,0.0615246650732552,0.027459722737612848,0.04273922087259942,0.06616155834340433,0.039306814873595296,0.03494110450285985,0.04695038351898258,0.0635787662122594,0.04406889747229029,0.034617758514257226,0.06005882117055409,0.04904248073110731,0.0468500276009173])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,2,4,5,6,7,8,10,12,15,18,19],[0.008101773017722172,0.22400260258264165,0.012857958649547608,0.3809726925253951,0.04158612397023884,0.030330022537158566,0.012662457049250824,0.10171669755393883,0.017610860848471178,0.013962837799693654,0.14174137698126102,0.014454596484680577])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |52.61 |\n",
      "|OneVsRest                     |52.64 |\n",
      "|LinearSVC                     |52.48 |\n",
      "|NaiveBayes                    |52.14 |\n",
      "|RandomForestClassifier        |52.52 |\n",
      "|GBTClassifier                 |52.37 |\n",
      "|DecisionTreeClassifier        |52.25 |\n",
      "|MultilayerPerceptronClassifier|52.80 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mW2VfeaturizedData  Results:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[ 1.25974016, -0.72084751, -0.59053498]])\n",
      "\n",
      "Intercept: [0.10147552275377064]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m -0.9376941066846864 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.7439540464184575,1.2726431355061019,0.8603071909313371]\n",
      "\u001b[1mIntercept: \u001b[0m 0.9376941066830347 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.7439540464199431,-1.2726431355046648,-0.8603071909315188]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[4.358968484310761,-1.4319862469353353,-2.6741333699972536]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3365430743162104,0.08264720184142127,0.5808097238423683])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3219246909903973,0.23996641537522045,0.43810889363438227])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.41420292919473584,0.03906013580797469,0.5467369349972895])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 39\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |54.93 |\n",
      "|OneVsRest                     |55.04 |\n",
      "|LinearSVC                     |54.70 |\n",
      "|NaiveBayes                    |50.44 |\n",
      "|RandomForestClassifier        |57.10 |\n",
      "|GBTClassifier                 |57.22 |\n",
      "|DecisionTreeClassifier        |57.11 |\n",
      "|MultilayerPerceptronClassifier|56.65 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for featureDF in featureDF_list:\n",
    "    print('\\033[1m' + featureDF.name,\" Results:\"+ '\\033[0m')\n",
    "    train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "    features = featureDF.select(['features']).collect()\n",
    "    # Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "    class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "    classes = class_count[0][0]\n",
    "\n",
    "    #set up your results table\n",
    "    columns = ['Classifier', 'Result']\n",
    "    vals = [(\"Place Holder\",\"N/A\")]\n",
    "    results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "        results = results.union(new_result)\n",
    "    results = results.where(\"Classifier!='Place Holder'\")\n",
    "    print(results.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb43d6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.41420292919473584,0.03906013580797469,0.5467369349972895])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Classifier: string, Result: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "featureDF = W2VfeaturizedData\n",
    "\n",
    "train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "features = featureDF.select(['features']).collect()\n",
    "\n",
    "# Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "#running this afain with generate all the objects need to play around with test data\n",
    "ClassTrainEval(classifier,features,classes,train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cd7111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Failures:\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|state |blurb                                                                                                                           |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|failed| one pen stroke at a time                                                                                                       |\n",
      "|failed|a san francisco based blog where artists from all over can come together to find inspiration as well as support each other      |\n",
      "|failed|aspiring canadian music producer and singersong writer who lives and loves music and art creating a debut alternative hip hop ep|\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      " \n",
      "Predicted Success:\n",
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|state |blurb                                                                                                                          |\n",
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|failed|a pilot program of five students focused on the interactions between ecology and humanity in the ceramic village of tamba japan|\n",
      "|failed|a public art studio embracing various fine arts and encouraging cultural crafts experienced students challenged art craft shows|\n",
      "|failed|a very serious game is an expansive experimental game the first iteration of this game will take place at nceca in providence  |\n",
      "+------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = DT_BestModel.transform(test)\n",
    "print(\"Predicted Failures:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=0\").orderBy(predictions[\"prediction\"].desc()).show(3,False)\n",
    "print(\" \")\n",
    "print(\"Predicted Success:\")\n",
    "predictions.select(\"state\",\"blurb\").filter(\"prediction=1\").orderBy(predictions[\"prediction\"].desc()).show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a19e6",
   "metadata": {},
   "source": [
    "#  What could be next?\n",
    "\n",
    "Once we have our model and all the vectorizer the sky is really the limit! We could do any of the following for starters:\n",
    "\n",
    "1. Allow a user to input their own \"blurb\" and we could return a prediction of whether or not it would pass\n",
    "2. If we had a time variable here, we could show the most popular words over time\n",
    "3. Provide this algorithim to Kickstarter for prescreening so they can prioritize entries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
